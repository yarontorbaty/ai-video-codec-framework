#!/usr/bin/env python3
"""
Adaptive Codec Agent - Uses LLM-Generated Code
This agent can replace its own implementation with better LLM-generated code.
"""

import os
import json
import logging
import time
import numpy as np
import cv2
from typing import Dict, Optional, Tuple

logger = logging.getLogger(__name__)


class AdaptiveCodecAgent:
    """
    Codec agent that can evolve by adopting LLM-generated compression code.
    """
    
    def __init__(self, resolution=(1920, 1080)):
        self.resolution = resolution
        self.current_implementation = None
        self.implementation_version = 0
        self.performance_history = []
        
        # Load current best implementation if it exists
        self.load_best_implementation()
    
    def load_best_implementation(self):
        """Load the current best implementation from disk."""
        impl_file = '/tmp/best_codec_implementation.json'
        if os.path.exists(impl_file):
            try:
                with open(impl_file, 'r') as f:
                    data = json.load(f)
                    self.current_implementation = data.get('code')
                    self.implementation_version = data.get('version', 0)
                    logger.info(f"‚úÖ Loaded implementation v{self.implementation_version}")
            except Exception as e:
                logger.warning(f"Could not load implementation: {e}")
    
    def save_implementation(self, code: str, metrics: Dict, commit_to_github: bool = True) -> Dict:
        """
        Save a new implementation as the current best.
        
        Returns:
            Dict with github_committed and github_commit_hash keys
        """
        impl_file = '/tmp/best_codec_implementation.json'
        self.implementation_version += 1
        
        data = {
            'version': self.implementation_version,
            'code': code,
            'metrics': metrics,
            'timestamp': str(np.datetime64('now'))
        }
        
        with open(impl_file, 'w') as f:
            json.dump(data, f, indent=2)
        
        self.current_implementation = code
        logger.info(f"üíæ Saved new implementation v{self.implementation_version}")
        
        github_info = {
            'github_committed': False,
            'github_commit_hash': None
        }
        
        # Commit to GitHub
        if commit_to_github:
            try:
                from agents.github_integration import GitHubIntegration
                
                github = GitHubIntegration()
                
                # Save code to actual file for committing
                codec_file = 'src/agents/evolved_codec.py'
                codec_path = os.path.join('/home/ec2-user/ai-video-codec', codec_file)
                
                with open(codec_path, 'w') as f:
                    f.write(f"# Evolved Codec v{self.implementation_version}\n")
                    f.write(f"# Auto-generated by LLM Autonomous System\n")
                    f.write(f"# Timestamp: {data['timestamp']}\n\n")
                    f.write(code)
                
                # Commit and push
                description = f"LLM evolved codec to v{self.implementation_version}"
                if 'bitrate_mbps' in metrics:
                    description += f" - {metrics['bitrate_mbps']:.2f} Mbps"
                if 'compression_ratio' in metrics:
                    description += f", {metrics['compression_ratio']:.2f}x compression"
                
                result = github.commit_and_push_evolution(
                    version=self.implementation_version,
                    files_changed=[codec_file, 'src/agents/evolved_codec.py'],
                    metrics=metrics,
                    description=description
                )
                
                if result['commit_success'] and result['push_success']:
                    logger.info(f"‚úÖ Committed to GitHub: {result['commit_hash'][:8]}")
                    github_info['github_committed'] = True
                    github_info['github_commit_hash'] = result.get('commit_hash')
                else:
                    logger.warning(f"‚ö†Ô∏è  GitHub commit failed: {result.get('error')}")
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Could not commit to GitHub: {e}")
                # Don't fail the save if GitHub commit fails
        
        return github_info
    
    def should_adopt_new_code(self, new_metrics: Dict) -> bool:
        """
        Decide if new LLM-generated code should replace current implementation.
        
        Comparison Strategy:
        1. First iteration: Compare against HEVC baseline (10 Mbps for 1080p)
        2. Subsequent iterations: Compare against previous best LLM code
        
        Adoption Criteria:
        - 10% better bitrate than previous iteration
        - OR 20% better compression ratio
        """
        HEVC_BASELINE_MBPS = 10.0  # HEVC at 10 Mbps for 1080p@30fps
        
        if not self.performance_history:
            # First iteration: Compare against HEVC baseline
            new_bitrate = new_metrics.get('bitrate_mbps', 999)
            if new_bitrate < HEVC_BASELINE_MBPS * 0.9:  # 10% better than HEVC
                logger.info(f"üéØ First version beats HEVC baseline: {new_bitrate:.2f} < {HEVC_BASELINE_MBPS} Mbps")
                return True
            else:
                logger.info(f"‚è∏Ô∏è  First version not better than HEVC: {new_bitrate:.2f} vs {HEVC_BASELINE_MBPS} Mbps")
                # Still adopt if it's reasonable (under 15 Mbps) to start iteration
                return new_bitrate < 15.0 and new_metrics.get('success', False)
        
        # Subsequent iterations: Compare against previous best
        best_prev = min(self.performance_history, key=lambda x: x.get('bitrate_mbps', 999))
        
        new_bitrate = new_metrics.get('bitrate_mbps', 999)
        new_quality = new_metrics.get('compression_ratio', 0)
        
        prev_bitrate = best_prev.get('bitrate_mbps', 999)
        prev_quality = best_prev.get('compression_ratio', 0)
        
        # Adoption criteria
        if new_bitrate < prev_bitrate * 0.9:  # 10% better bitrate
            logger.info(f"üéØ New code is {(1 - new_bitrate/prev_bitrate)*100:.1f}% better than v{self.implementation_version}!")
            return True
        
        if new_quality > prev_quality * 1.2:  # 20% better compression ratio
            logger.info(f"üéØ New code has {(new_quality/prev_quality - 1)*100:.1f}% better compression than v{self.implementation_version}!")
            return True
        
        logger.info(f"‚è∏Ô∏è  New code not better: {new_bitrate:.2f} vs {prev_bitrate:.2f} Mbps")
        return False
    
    def test_generated_code(self, code: str, function_name: str = 'compress_video_frame') -> Tuple[bool, Optional[Dict]]:
        """
        Test LLM-generated code and return performance metrics.
        """
        import time
        import os
        import io
        import sys
        
        # Capture logs
        log_capture = io.StringIO()
        log_handler = logging.StreamHandler(log_capture)
        log_handler.setLevel(logging.INFO)
        logger.addHandler(log_handler)
        
        try:
            from utils.code_sandbox import CodeSandbox
            from utils.log_analyzer import LogAnalyzer
            
            # Save code version regardless of outcome
            timestamp = int(time.time())
            version_dir = '/tmp/codec_versions'
            os.makedirs(version_dir, exist_ok=True)
            
            version_file = f'{version_dir}/codec_attempt_{timestamp}.py'
            with open(version_file, 'w') as f:
                f.write(f"# Codec Version Attempt - {time.ctime()}\n")
                f.write(f"# Timestamp: {timestamp}\n")
                f.write(f"# Function: {function_name}\n\n")
                f.write(code)
            
            logger.info(f"üìù Saved code version to {version_file}")
            
            sandbox = CodeSandbox(timeout=30)
            analyzer = LogAnalyzer()
            
            # Validate code
            is_valid, error = sandbox.validate_code(code, save_attempt=True)
            if not is_valid:
                logger.error(f"‚ùå CODE VALIDATION FAILED")
                logger.error(f"   Error: {error}")
                logger.error(f"   File: {version_file}")
                logger.error(f"   First 500 chars:\n{code[:500]}")
                
                # Capture logs and analyze failure
                logs = log_capture.getvalue()
                analysis = analyzer.analyze_failure(
                    experiment_id=f"validation_{timestamp}",
                    experiment_type='code_validation',
                    error_message=error,
                    logs=logs,
                    code_snippet=code
                )
                
                # Save validation failure details with analysis
                failure_file = f'{version_dir}/validation_failure_{timestamp}.txt'
                with open(failure_file, 'w') as f:
                    f.write(f"Validation Failure - {time.ctime()}\n")
                    f.write(f"{'='*60}\n\n")
                    f.write(f"Error: {error}\n\n")
                    f.write(f"LLM Analysis:\n{'-'*60}\n")
                    f.write(f"Category: {analysis.get('failure_category', 'unknown')}\n")
                    f.write(f"Root Cause: {analysis.get('root_cause', 'N/A')}\n")
                    f.write(f"Fix: {analysis.get('fix_suggestion', 'N/A')}\n")
                    f.write(f"Severity: {analysis.get('severity', 'unknown')}\n\n")
                    f.write(f"Code:\n{'-'*60}\n{code}\n")
                
                # Store analysis for dashboard display
                if not hasattr(self, '_last_failure_analysis'):
                    self._last_failure_analysis = {}
                self._last_failure_analysis = analysis
                
                return False, None
            
            # Test on sample frames from real video
            # Option 1: Use synthetic test frames (current - fast for testing)
            # Option 2: Load actual frames from SOURCE_HD_RAW.mp4 (TODO: implement)
            test_frames = [
                np.random.randint(0, 255, (1080, 1920, 3), dtype=np.uint8),  # Random noise
                np.zeros((1080, 1920, 3), dtype=np.uint8),  # Black frame
                np.ones((1080, 1920, 3), dtype=np.uint8) * 128,  # Gray frame
            ]
            # TODO: Replace with actual video frames:
            # frames = load_source_video_frames('s3://ai-video-codec-videos-580473065386/source/SOURCE_HD_RAW.mp4', num_frames=3)
            
            total_original_size = 0
            total_compressed_size = 0
            successes = 0
            last_error = "No error"
            
            for i, frame in enumerate(test_frames):
                config = {'quality': 50, 'max_edges': 500}  # Match LLM's expected config params
                success, result, exec_error = sandbox.execute_function(
                    code, function_name, (frame, i, config)  # Pass as tuple: (frame, frame_index, config)
                )
                
                # Save error for analysis if execution failed
                if not success and exec_error:
                    last_error = exec_error
                
                if success and result:
                    original_size = frame.nbytes
                    
                    # Handle both dict and bytes return types
                    if isinstance(result, dict):
                        compressed_size = len(result.get('compressed', b''))
                    elif isinstance(result, bytes):
                        compressed_size = len(result)
                    else:
                        logger.warning(f"Unexpected result type: {type(result)}")
                        continue
                    
                    total_original_size += original_size
                    total_compressed_size += compressed_size
                    successes += 1
                    
                    logger.info(f"Test {i+1}: {original_size} ‚Üí {compressed_size} bytes")
            
            if successes == 0:
                # Analyze execution failure
                logs = log_capture.getvalue()
                analysis = analyzer.analyze_failure(
                    experiment_id=f"execution_{timestamp}",
                    experiment_type='code_execution',
                    error_message=last_error,
                    logs=logs,
                    code_snippet=code
                )
                self._last_failure_analysis = analysis
                logger.error(f"‚ùå All test executions failed")
                logger.error(f"   Analysis: {analysis.get('failure_category', 'unknown')} - {analysis.get('root_cause', 'N/A')}")
                return False, None
            
            # Calculate metrics
            compression_ratio = total_original_size / total_compressed_size if total_compressed_size > 0 else 0
            bitrate_mbps = (total_compressed_size * 8) / (len(test_frames) * 1_000_000) * 30  # Assuming 30fps
            
            metrics = {
                'success': True,
                'compression_ratio': compression_ratio,
                'bitrate_mbps': bitrate_mbps,
                'test_frames': successes,
                'avg_compressed_size': total_compressed_size / successes
            }
            
            logger.info(f"üìä Metrics: {compression_ratio:.2f}x compression, {bitrate_mbps:.2f} Mbps")
            
            return True, metrics
            
        except Exception as e:
            # Analyze general exception
            logs = log_capture.getvalue() if 'log_capture' in locals() else str(e)
            analysis = analyzer.analyze_failure(
                experiment_id=f"exception_{int(time.time())}",
                experiment_type='code_testing',
                error_message=str(e),
                logs=logs,
                code_snippet=code if 'code' in locals() else ''
            )
            self._last_failure_analysis = analysis
            logger.error(f"‚ùå Error testing generated code: {e}")
            logger.error(f"Analysis: {analysis.get('failure_category', 'unknown')} - {analysis.get('root_cause', 'N/A')}")
            return False, None
        finally:
            # Clean up log handler
            if 'log_handler' in locals() and 'logger' in dir():
                logger.removeHandler(log_handler)
    
    def evolve_with_llm_code(self, generated_code_info: Dict) -> Dict:
        """
        Evaluate and potentially adopt LLM-generated code.
        
        Returns:
            Dict with evolution results (adopted/rejected, metrics, etc.)
        """
        if not generated_code_info or 'code' not in generated_code_info:
            return {'status': 'no_code', 'adopted': False}
        
        code = generated_code_info['code']
        function_name = generated_code_info.get('function_name', 'compress_video_frame')
        
        logger.info("üß¨ Evaluating LLM-generated code for evolution...")
        
        # Test the new code
        success, metrics = self.test_generated_code(code, function_name)
        
        if not success or not metrics:
            # Include failure analysis if available
            failure_analysis = getattr(self, '_last_failure_analysis', {})
            return {
                'status': 'test_failed',
                'adopted': False,
                'reason': 'Code testing failed or produced invalid results',
                'failure_analysis': failure_analysis
            }
        
        # Decide if we should adopt it
        should_adopt = self.should_adopt_new_code(metrics)
        
        if should_adopt:
            github_info = self.save_implementation(code, metrics)
            self.performance_history.append(metrics)
            
            logger.info(f"üéâ EVOLUTION SUCCESS! Adopted new implementation v{self.implementation_version}")
            
            improvement = self._calculate_improvement(metrics)
            
            # Create summary
            summary = f"LLM evolved codec to v{self.implementation_version}"
            if improvement.get('bitrate_reduction_percent'):
                summary += f" - {abs(improvement['bitrate_reduction_percent']):.1f}% bitrate reduction"
            if metrics.get('bitrate_mbps'):
                summary += f", {metrics['bitrate_mbps']:.2f} Mbps"
            if metrics.get('compression_ratio'):
                summary += f", {metrics['compression_ratio']:.1f}x compression"
            
            return {
                'status': 'adopted',
                'adopted': True,
                'version': self.implementation_version,
                'metrics': metrics,
                'improvement': improvement,
                'summary': summary,
                'deployment_status': 'deployed',
                'github_committed': github_info['github_committed'],
                'github_commit_hash': github_info['github_commit_hash']
            }
        else:
            self.performance_history.append(metrics)
            
            logger.info("‚è≠Ô∏è  New code not better than current - keeping existing implementation")
            
            # Create rejection summary
            reason_detail = "No improvement in compression ratio or bitrate"
            if metrics.get('bitrate_mbps') and len(self.performance_history) > 0:
                prev_bitrate = self.performance_history[-1].get('bitrate_mbps', 0)
                if metrics['bitrate_mbps'] >= prev_bitrate:
                    reason_detail = f"Bitrate {metrics['bitrate_mbps']:.2f} Mbps not better than current {prev_bitrate:.2f} Mbps"
            
            return {
                'status': 'rejected',
                'adopted': False,
                'reason': 'Performance not better than current implementation',
                'metrics': metrics,
                'summary': f"Code generated but rejected: {reason_detail}",
                'deployment_status': 'not_deployed',
                'github_committed': False,
                'github_commit_hash': None
            }
    
    def _calculate_improvement(self, new_metrics: Dict) -> Dict:
        """Calculate improvement over previous best."""
        if len(self.performance_history) < 2:
            return {'first_implementation': True}
        
        prev = self.performance_history[-2]
        new = new_metrics
        
        bitrate_improvement = ((prev.get('bitrate_mbps', 999) - new.get('bitrate_mbps', 999)) / 
                               prev.get('bitrate_mbps', 999) * 100)
        
        return {
            'bitrate_reduction_percent': bitrate_improvement,
            'compression_ratio_change': new.get('compression_ratio', 0) / prev.get('compression_ratio', 1)
        }
    
    def run_real_experiment_with_code(self, code: str, duration: float = 10.0, fps: float = 30.0, resolution: tuple = (1920, 1080)) -> Dict:
        """
        Run a real experiment using LLM-generated code.
        
        This is THE METHOD that actually uses the LLM code for compression!
        
        Args:
            code: LLM-generated compress_video_frame() function
            duration: Video duration in seconds
            fps: Frames per second
            resolution: Video resolution (width, height)
            
        Returns:
            Dict with status, metrics, and results
        """
        try:
            logger.info(f"üß™ Running real experiment with LLM code...")
            
            # Generate procedural test video
            from agents.procedural_generator import ProceduralCompressionAgent
            proc_agent = ProceduralCompressionAgent(resolution=resolution, config={})
            
            timestamp = int(time.time())
            input_video_path = f"/tmp/test_input_{timestamp}.mp4"
            output_compressed_path = f"/tmp/test_output_{timestamp}.dat"
            
            logger.info(f"  üìπ Generating test video...")
            proc_result = proc_agent.generate_procedural_video(
                input_video_path,
                duration=duration,
                fps=fps
            )
            
            if proc_result.get('status') != 'completed':
                raise Exception("Failed to generate test video")
            
            logger.info(f"  üóúÔ∏è  Compressing with LLM code...")
            
            # Now compress the test video using the LLM code
            from utils.code_sandbox import CodeSandbox
            import cv2
            
            cap = cv2.VideoCapture(input_video_path)
            video_fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            compressed_data = []
            sandbox = CodeSandbox(timeout=60)
            
            logger.info(f"  üìä Compressing {frame_count} frames...")
            
            for i in range(frame_count):
                ret, frame = cap.read()
                if not ret:
                    break
                
                config = {'quality': 0.8, 'frame_index': i}
                # execute_function expects: (code, function_name, args_tuple, kwargs_dict)
                success, result, error = sandbox.execute_function(
                    code,
                    'compress_video_frame',
                    (frame, i, config)  # Pass as TUPLE
                )
                
                if success and result:
                    # Extract compressed bytes
                    if isinstance(result, dict):
                        compressed_data.append(result.get('compressed', result.get('return_value', b'')))
                    elif isinstance(result, bytes):
                        compressed_data.append(result)
                    else:
                        compressed_data.append(b'')
                else:
                    logger.warning(f"    Frame {i} compression failed: {error}")
                    compressed_data.append(b'')
            
            cap.release()
            
            # Calculate metrics
            total_compressed_size = sum(len(d) for d in compressed_data)
            duration_actual = frame_count / video_fps
            bitrate_mbps = (total_compressed_size * 8) / (duration_actual * 1_000_000)
            
            logger.info(f"  ‚úÖ Compression complete!")
            logger.info(f"  üìà Compressed size: {total_compressed_size / 1_000_000:.2f} MB")
            logger.info(f"  üìà Bitrate: {bitrate_mbps:.4f} Mbps")
            
            # Clean up
            import os
            try:
                os.remove(input_video_path)
            except:
                pass
            
            return {
                'status': 'completed',
                'real_metrics': {
                    'bitrate_mbps': bitrate_mbps,
                    'file_size_mb': total_compressed_size / 1_000_000,
                    'compressed_size_bytes': total_compressed_size,
                    'duration': duration_actual,
                    'fps': video_fps,
                    'total_frames': frame_count,
                    'resolution': f"{resolution[0]}x{resolution[1]}"
                }
            }
            
        except Exception as e:
            logger.error(f"  ‚ùå Experiment with LLM code failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
            return {
                'status': 'failed',
                'error': str(e),
                'real_metrics': {}
            }
    
    def compress_video(self, input_path: str, output_path: str) -> Dict:
        """
        Compress video using current best implementation.
        Falls back to default if no implementation available.
        """
        if not self.current_implementation:
            logger.warning("No evolved implementation available - using baseline")
            return self._baseline_compression(input_path, output_path)
        
        try:
            from utils.code_sandbox import CodeSandbox
            
            # Load video
            cap = cv2.VideoCapture(input_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            compressed_data = []
            sandbox = CodeSandbox(timeout=60)
            
            logger.info(f"Compressing {frame_count} frames with evolved codec v{self.implementation_version}...")
            
            for i in range(frame_count):
                ret, frame = cap.read()
                if not ret:
                    break
                
                config = {'quality': 0.8}
                success, result, error = sandbox.execute_function(
                    self.current_implementation,
                    'compress_video_frame',
                    frame,
                    config
                )
                
                if success and result:
                    compressed_data.append(result.get('compressed', b''))
            
            cap.release()
            
            # Save compressed data
            total_size = sum(len(d) for d in compressed_data)
            duration = frame_count / fps
            bitrate_mbps = (total_size * 8) / (duration * 1_000_000)
            
            with open(output_path, 'wb') as f:
                for data in compressed_data:
                    f.write(data)
            
            return {
                'status': 'success',
                'implementation_version': self.implementation_version,
                'bitrate_mbps': bitrate_mbps,
                'file_size_bytes': total_size,
                'frames_compressed': len(compressed_data)
            }
            
        except Exception as e:
            logger.error(f"Error using evolved implementation: {e}")
            return self._baseline_compression(input_path, output_path)
    
    def _baseline_compression(self, input_path: str, output_path: str) -> Dict:
        """Fallback baseline compression."""
        # Simple copy as baseline
        import shutil
        shutil.copy(input_path, output_path)
        
        size = os.path.getsize(output_path)
        
        return {
            'status': 'baseline_fallback',
            'implementation_version': 0,
            'bitrate_mbps': (size * 8) / (10.0 * 1_000_000),
            'file_size_bytes': size
        }

